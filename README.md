# ğŸš— CARLOS  
### Vision-Based Autonomous Mobile Platform  

Real-time lane detection and traffic sign recognition system running on Raspberry Pi 4.

---

## ğŸ“Œ About the Project

CARLOS (Cognitive Autonomous Road-Learning Operating System) is a small-scale autonomous mobile platform developed as an engineering thesis project.

The system is designed to:

- Follow a marked lane using a monocular camera  
- Detect and classify selected traffic signs  
- Adapt steering in real time using differential drive control  
- Operate autonomously without human intervention  

This repository contains the **complete software stack** running on the robot.

---

## ğŸ–¼ï¸ Full Platform Overview

<p align="center">
  <img src="images/carlos_full.png" width="600">
</p>

CARLOS autonomous mobile platform integrating vision system, control logic and differential drive hardware.

---

## ğŸ§  System Overview

CARLOS integrates:

- Computer Vision (OpenCV-based)
- Real-time control logic
- PWM motor control
- Raspberry Pi hardware interface
- Differential drive kinematics

### High-Level Pipeline
  ```python
  Camera Frame
  â†“
  Lane Detection â†’ Steering Error
  Sign Detection â†’ Event Info
  â†“
  Drive Control (P-controller + fallback)
  â†“
  Motor PWM Output


---

## ğŸ›£ Lane Detection Module

Implemented using classical computer vision techniques (no machine learning):

- BGR â†’ HSV thresholding
- Morphological filtering
- Perspective transform (birdâ€™s-eye view)
- Histogram-based lane localization
- Polynomial fitting
- Lateral & heading error estimation

**Output:**
- Lane center offset
- Lane validity flag
- Steering correction input

Example of real-time lane detection with perspective transform and polynomial fitting:

<p align="center">
  <img src="images/lane_output.png" width="700">
</p>

The image above shows:
- Birdâ€™s-eye view transformation
- Lane segmentation mask
- Fitted lane polynomial
- Center offset estimation

---

## ğŸš¸ Traffic Sign Detection Module

Multi-stage detection pipeline:

1. Edge detection (Canny)
2. Contour extraction
3. Shape classification (triangle / circle / octagon)
4. HSV dominant color filtering
5. ORB feature matching against internal sign database

**Supported classes:**
- STOP
- Speed limits
- Warning signs
- Mandatory signs

**Output:**
-Classified sign label
-confidence score

Example of traffic sign detection with contour analysis and ORB matching:

<p align="center">
  <img src="images/sign_output.png" width="700">
</p>

The detection pipeline visualizes:
- Extracted contour
- Bounding box
- Classified sign label
- Confidence score

---

## ğŸ› Control Logic

The `Drive_Control` module implements:

- Proportional steering controller
- Differential speed mapping:

  ```python
  left  = base_speed - steering
  right = base_speed + steering

- Steering saturation limits
- Emergency fallback mode when lane detection becomes unreliable

## âš™ï¸ Hardware Platform

The software runs on a fully integrated autonomous mobile platform consisting of:

- **Raspberry Pi 4 Model B** â€“ main computing unit  
- **CSI 5MP camera with 180Â° wide-angle lens** â€“ monocular vision system  
- **Dual N20 DC gear motors (75:1)** â€“ differential drive propulsion  
- **Cytron MDD3A motor driver** â€“ dual-channel H-bridge control  
- **Differential drive configuration** â€“ independent left/right wheel control  
- **Separated power architecture** â€“ independent supplies for logic and motors  

The hardware architecture was designed to support real-time vision processing while maintaining stable motor control under embedded constraints.

---

## ğŸ›  Technologies Used

- **Python**
- **OpenCV**
- **NumPy**
- **GPIO + PWM motor control**
- **Object-Oriented Programming (modular architecture)**
- **Real-time image processing on embedded Linux (Raspberry Pi OS)**

The system avoids machine learning by design and relies entirely on deterministic computer vision and control algorithms.

---

## ğŸ”¬ Engineering Challenges Addressed

During development, several real-world engineering challenges were identified and addressed:

- Wide-angle lens distortion affecting contour-based sign detection  
- Sensitivity of HSV segmentation to lighting conditions  
- Real-time processing constraints on Raspberry Pi hardware  
- Steering instability under partial lane loss  
- Separation of perception, decision, and execution layers  
- Power supply noise isolation between motors and logic system  

The project focuses not only on functionality but also on robustness under practical embedded conditions.

---

## ğŸš€ Current Status

- âœ” Fully integrated hardware + software system  
- âœ” Real-time lane following  
- âœ” Real-time traffic sign recognition  
- âœ” Adaptive steering control  
- âœ” Laboratory validation completed  

### Ongoing Improvements

- Crossroad detection refinement  
- Improved fallback robustness  
- Lens distortion correction  
- Sign-based speed adaptation  
- Performance optimization for higher frame rate stability  

---

## â–¶ How to Run

1. Clone the repository:
  ```python
  git clone https://github.com/Tomasz-Marek/Autonomous_car.git
  cd CARLOS


2. Create and activate a virtual environment:
  ```python
  python -m venv .venv
  source .venv/bin/activate # Linux / macOS
  ..venv\Scripts\activate # Windows


3. Install dependencies:
  ```python
  pip install -r requirements.txt

4. Run the main control loop:
  ```python
  python Python_codes/Main.py


Ensure that the Raspberry Pi camera and motor driver are properly connected before execution.

---

## ğŸ“ Background

Developed as part of an engineering thesis focused on:

> Vision-based autonomous navigation and adaptive control in small-scale mobile platforms.

The project integrates mechanical design, embedded electronics, real-time computer vision, and control theory into a cohesive autonomous system.

---

## ğŸ“„ License

MIT License
